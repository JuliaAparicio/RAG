# ğŸ§  RAG System â€“ Retrieval-Augmented Generation

ImplementaÃ§Ã£o personalizada de um sistema de Retrieval-Augmented Generation (RAG), capaz de integrar mÃºltiplas fontes de conhecimento e gerar respostas contextualizadas com base em documentos externos.

---

## ğŸš€ Sobre o Projeto

Este projeto implementa um pipeline de RAG que combina:

- Busca semÃ¢ntica em documentos
- Banco de vetores (vector database)
- Modelo de linguagem (LLM)
- GeraÃ§Ã£o de respostas contextualizadas

A proposta foi personalizar uma base inicial fornecida em aula e expandir a arquitetura para integrar diferentes tipos de fontes de conhecimento.

---

## ğŸ“š Fontes Utilizadas

O sistema foi configurado para processar e consultar:

- ğŸ“„ PDF sobre Ãlgebra Booleana  
- ğŸ¥ VÃ­deo do YouTube sobre Energia Solar  

Os conteÃºdos sÃ£o convertidos em texto, divididos em trechos menores (chunking) e armazenados em um banco vetorial.

---

## âš™ï¸ Como Funciona

1. **IngestÃ£o de Dados**
   - ExtraÃ§Ã£o de texto do PDF
   - TranscriÃ§Ã£o do vÃ­deo do YouTube
   - DivisÃ£o do conteÃºdo em chunks

2. **VetorizaÃ§Ã£o**
   - ConversÃ£o dos trechos em embeddings
   - Armazenamento em banco de vetores

3. **Consulta**
   - O usuÃ¡rio faz uma pergunta
   - O sistema busca os trechos semanticamente mais relevantes
   - Os trechos sÃ£o enviados junto ao prompt para o modelo de linguagem

4. **GeraÃ§Ã£o da Resposta**
   - O LLM gera uma resposta baseada no contexto recuperado
   - ReduÃ§Ã£o de alucinaÃ§Ãµes
   - Respostas mais precisas e fundamentadas

---

## ğŸ§  Conceitos Aplicados

- Retrieval-Augmented Generation (RAG)
- Embeddings
- Busca semÃ¢ntica
- Engenharia de Prompt
- Chunking Strategy
- Context Injection
- ReduÃ§Ã£o de alucinaÃ§Ã£o em LLMs

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python
- Biblioteca de embeddings
- Banco de vetores
- API de modelo de linguagem
- Processamento de texto
- TranscriÃ§Ã£o de vÃ­deo

---

## ğŸ¯ Objetivo do Projeto

Explorar como a personalizaÃ§Ã£o de um pipeline RAG pode:

- Melhorar a precisÃ£o de respostas
- Integrar diferentes fontes de conhecimento
- Criar sistemas de IA mais confiÃ¡veis
- Aplicar conceitos avanÃ§ados de NLP na prÃ¡tica

---

## ğŸ” Aprendizados

Mesmo partindo de uma base fornecida, a personalizaÃ§Ã£o da arquitetura, da estratÃ©gia de chunking e do fluxo de consulta foi fundamental para:

- Melhorar a qualidade das respostas
- Entender o funcionamento interno de sistemas baseados em LLM
- Desenvolver visÃ£o crÃ­tica sobre limitaÃ§Ãµes e melhorias possÃ­veis

---

## â–¶ï¸ Como Executar

```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>

# Instale as dependÃªncias
pip install -r requirements.txt

# Execute o projeto
python main.py
